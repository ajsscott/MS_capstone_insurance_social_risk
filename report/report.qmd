---
title: "Predicting Auto Insurance Risk Using Gradient Boosting"
subtitle: "Analyzing Socio-Economic Factors in Car Crashes for New York City"

author:
  - name: AJ Strauman-Scott
    orcid: "0009-0000-9091-0697"
    email: {ajstraumanscott@pm.me}
    
    affiliations:
      - id: cuny
        name: City University Of New York (CUNY)
        department: Department of Data Science
        city: New York City
        country: United States of America

abstract: |
  This study explores the use of the gradient boosting model XGBoost to predict auto insurance risk by integrating socio-economic variables from publicly available data. By treating crash frequency as proxy for insurance claims, the project aims to identify key neighborhood-level factors influencing risk. The dataset, encompassing 13,518 census tract-by-year observations from 2018 to 2023, captures demographic, economic, housing, and commuting indicators alongside engineered interaction variables. Optuna hyperparameter tuning and SHAP-based explainability reveal that post-pandemic traffic dynamics, median gross rent, percent  of  a population in the labor-force, and the interaction of poverty with vehicle ownership are significant predictors of crash risk. While the model achieves moderate predictive accuracy ($R^2$ = 0.26), its interpretability highlights socio-economic disparities that influence urban traffic safety. The findings underscore the potential of open data-driven models for portfolio-level risk assessment and urban safety planning, while cautioning against direct use for individual underwriting due to fairness and legal concerns. 

keywords: 
    - Gradient Boosting
    - XGBoost
    - SHAP explainability
    - hyperparameter optimization
    - auto insurance risk
    - American Community Survey (ACS)
    - NYC Open Data
    - predictive modeling
    - socio-economic predictors
    - crash modeling

date: last-modified
bibliography: bibliography.bib

format:
  elsevier-pdf:
    keep-tex: true
    citation-style: authoryear 
---

## Introduction {#sec-intro}

Accurate insurance risk modeling is critical for setting fair premiums, mitigating losses, and ensuring financial stability within the insurance industry \citep{henckaerts, clemente}. Predicting claim frequency not only supports pricing but also enables insurers to manage portfolio-level risk and optimize resource allocation \citep{mohamed}.

New York City (NYC) presents a complex urban environment where traffic risks are shaped by socio-economic factors, dense infrastructure, and scaling dynamics typical of large metropolitan areas \citep{cabrera, bettencourt}. The availability of open datasets—such as NYC’s Motor Vehicle Collision (MVC) data and socio-economic indicators from the American Community Survey (ACS)—offers a unique opportunity to develop proxy models for insurance claim risk. These data sources provide detailed insights into crash frequency, commuting behaviors, and neighborhood-level demographics \citep{adeniyi, brubacher}.

Traditional actuarial methods, such as Generalized Linear Models (GLMs), have long been the foundation of risk pricing and underwriting due to their interpretability and regulatory acceptance \citep{henckaerts}. However, GLMs are limited in their ability to capture non-linear relationships and interactions among complex predictors like socio-economic factors, urban infrastructure, and driving behavior \citep{clemente}. These limitations are particularly pronounced in urban contexts, where crash risk is shaped by heterogeneous population dynamics and localized factors \citep{cabrera, brubacher}.

Recent studies and systematic reviews confirm that machine learning methods, particularly ensemble models like Gradient Boosting Machines (GBMs), outperform traditional GLMs for predicting both claim frequency and severity \citep{clemente, mohamed, behboudi}. These models are capable of handling mixed data types (categorical and continuous) and capturing complex feature interactions that linear models often miss.

To address the interpretability challenge of “black box” ML models, SHAP (SHapley Additive exPlanations) offers a principled framework for feature attribution, allowing insurers and policymakers to understand both global feature importance and instance-level predictions \citep{lundberg, dong, ning}. This combination of high-performance prediction and explainability provides a strong foundation for modern risk modeling \citep{kim}.

Despite the growing body of work applying GBMs to insurance modeling, few studies integrate publicly available crash data with socio-economic indicators to model claim-related risks specifically for the automotive insurance sector. Most research remains limited to proprietary policyholder data \citep{henckaerts, mohamed}, while systematic reviews highlight that few studies combine open crash data with socio-economic indicators in insurance modeling \citep{ali, behboudi}.

This study aims to integrate ACS socio-economic features with NYC MVC crash data to develop an explainable gradient boosting framework for measureing social risk for automotive insurance and urban policy. The ultimate goal is to identify key socio-economic and transportation predictors that drive claim frequency.

The remainder of this paper is organized as follows: Section 2 reviews prior work on ML in insurance risk modeling, model explainability, and literature gaps; Section 3 details the data sources, key metrics, modeling approach, and SHAP-based explainability; Section 4 reports the results including hyperparameter tuning results, model performance, and feature importance; Section 5 discusses the findings in relation to existing research and industry applications; and Section 6 concludes with key contributions, limitations, and directions for future research.

## Related Work {#sec-lit-review}

### **Machine Learning in Insurance Risk Modeling**

The transition from traditional actuarial models such as Generalized Linear Models (GLMs) to machine learning (ML) approaches has marked a significant evolution in insurance risk modeling. GLMs have historically served as the backbone for pricing and claim prediction due to their interpretability and regulatory acceptance. However, they are limited by their linearity and inability to naturally capture complex interactions and nonlinear relationships among predictors, such as driver demographics, vehicle characteristics, socio-economic factors, and driving behavior. As \citet{clemente} note, while GLMs remain effective for modeling claim severity with smaller and noisier datasets, they often underperform compared to ensemble methods when modeling claim frequency, where nonlinearities and heterogeneous risk patterns are prevalent. Similarly, \citet{jonkheijm} demonstrated that tree-based models, especially XGBoost, substantially improved predictive accuracy over linear regression, particularly when incorporating both actuarial features (e.g., policyholder age, vehicle value) and behavioral indicators.

Recent studies have validated the predictive superiority of ML methods—such as random forests, GBMs, and neural networks—over traditional actuarial models. GBMs, such as XGBoost and LightGBM, have emerged as particularly effective tools in auto insurance risk modeling \citep{henckaerts}. Their iterative boosting framework enables them to handle mixed data types (categorical and continuous) and capture intricate patterns that GLMs and single decision trees may miss. \citet{clemente} applied gradient boosting to both claim frequency and severity modeling, demonstrating significant performance gains in frequency prediction over Poisson-based GLMs. Similarly, \citet{jonkheijm} employed XGBoost for forecasting individual claim amounts, outperforming both regression trees and random forests.

### **Use of Crash and Socio-Economic Data**

Crash data has been widely recognized as a reliable proxy for insurance claim frequency, given the direct link between the occurrence of traffic accidents and subsequent claims filed by policyholders. Studies utilizing police crash reports, telematics, and open transportation datasets consistently demonstrate strong correlations between crash frequency and insurance risk metrics \citep{takale}. The integration of socio-economic features—including income levels, commuting patterns, vehicle ownership rates, and population density—has been shown to enhance the explanatory power of crash and claim prediction models.

For example, \citet{adeniyi} utilized a decade of NYC crash data (2013–2023) to identify key predictors of accident severity—such as unsafe speed, alcohol involvement, and adverse weather—which align closely with the variables insurers use to model claim likelihood. Similarly, \citet{dong} applied boosting-based ensemble models to traffic injury severity prediction, finding that vehicle type, collision mode, and environmental conditions strongly influenced both injury outcomes and, by extension, potential claim costs. \citet{brubacher} conducted a geospatial analysis of 10 years of crashes in British Columbia and found that regions with lower income and higher socio-economic deprivation exhibited higher rates of pedestrian crashes, severe injuries, and fatalities, reflecting disparities in road safety linked to infrastructure quality and enforcement intensity. \citet{cabrera} expanded on this by identifying superlinear scaling of road accidents in urban areas, where higher population densities led to disproportionate increases in crash frequency, especially for minor collisions. These findings are directly relevant for insurers, as they imply that socio-economic and urban structural factors—such as commuting patterns or access to public transit—can serve as proxies for underlying risk exposure.

Urban-focused studies have further illuminated the unique risk dynamics in metropolitan environments like New York City, Chicago, and London, where complex traffic patterns, dense road networks, and high pedestrian activity elevate accident risk. \citet{adeniyi} analyzed NYC crash data to show how the COVID-19 pandemic altered accident patterns, with fewer total crashes but an increase in injury severity due to higher vehicle speeds on less congested roads. \citet{feng}, studying UK traffic data, emphasized the value of big data platforms and spatial clustering techniques (e.g., accident hotspot detection) to identify urban risk zones, a concept that parallels insurer efforts to assess region-based risk for underwriting.

### **Explainability in GBM Models**

In high-stakes fields such as insurance pricing, underwriting, and claims management, the interpretability of ML models is not only a technical preference but also a regulatory and business requirement. Insurers must be able to justify rating factors and risk scores to regulators, policyholders, and internal stakeholders. Traditional actuarial models like GLMs are naturally interpretable due to their linear structure and explicit coefficient estimates. However, modern ML models—such as gradient boosting or neural networks—are often criticized as “black boxes,” complicating the explanation of predictions that influence financial decisions or customer premiums. Regulatory frameworks, including the EU’s General Data Protection Regulation (GDPR) and U.S. state-level insurance guidelines, increasingly require transparency in algorithmic decision-making, further amplifying the need for explainable AI (shortened to XAI). \citet{henckaerts} further underscore this, showing that variable importance plots and PDPs can yield actionable insights into driver and policyholder risk factors, blending predictive power with interpretability.

Among XAI methods, SHAP (SHapley Additive exPlanations) has become the state-of-the-art framework for interpreting complex ML models. Developed by \citet{lundberg}, SHAP is grounded in cooperative game theory, assigning each feature a Shapley value that quantifies its contribution to individual predictions. Unlike traditional feature importance metrics—such as Gini importance in random forests or split gain in XGBoost—SHAP accounts for both main effects and feature interactions, offering a consistent and additive explanation of how variables drive model outputs.

In the insurance domain, SHAP has been widely applied to interpret models for claims prediction, fraud detection, and risk scoring. \citet{dong} used SHAP in conjunction with boosting-based models (LightGBM and CatBoost) to analyze the contribution of driver age, vehicle type, and collision type to injury severity predictions, providing insights that aligned with domain expertise. Similarly, \citet{ning} demonstrated how Shapley Variable Importance Cloud (ShapleyVIC) builds on SHAP principles to assess variable significance with uncertainty intervals, enabling fairer and more transparent risk predictions. 

### **Gaps in the Literature**

While ML methods—particularly ensemble models like gradient boosting—have gained traction in insurance risk modeling, there is a notable absence of studies that combine socio-economic and crash data for claim risk prediction. Most existing research focuses on proprietary insurance datasets containing policyholder and vehicle information \citep{clemente, henckaerts, jonkheijm}. This gap limits the development of robust, regionally sensitive models that capture the real-world interaction between crash frequency and socio-economic indicators.

## Materials and Methods {#sec-methods}

### **Data Sources**

The data sources and preprocessing steps are designed to replicate key factors used in actuarial risk models while incorporating broader socio-economic and regional variables.

#### **Crash Data (Claim Proxies)**

Crash data is obtained from the NYC Motor Vehicle Collisions (MVC) Open Data Portal, covering the years 2018–2023. Each record includes details such as crash location, number of injuries and fatalities, vehicle type, and contributing factors. These variables are well-documented predictors of both accident severity and insurance claims \citep{adeniyi, dong}.

Crash frequency was aggregated at the 2020 census tract level and normalized by tract-level population to compute crashes per 1,000 resident. This metric will replace claim frequency \citep{brubacher}.

#### **Socio-Economic Data (ACS Features)**

Socio-economic variables are drawn from the ACS 5-year estimates (2018–2023) at the 2020 census tract level. The variables include demographic composition (e.g., % male, % white, % Hispanic, % foreign-born), age distribution, and income indicators. Additional features include median gross rent, housing tenure, educational attainment, employment metrics, and transportation factors. 

```{r table1}
#| echo: false
#| warning: false
#| message: false
library(knitr)

acs_table_summary <- data.frame(
  `ACS` = c(
    "B01001", "B08301", "B08303",
    "B19001", "B25010", "B25044", "C24010",
    "C24030", "B15003", "B17001", "B02001", "B03002",
    "B18101", "B16005", "B23025", "B25064"
  ),
  Description = c(
    "Age and Sex",
    "Transportation to Work",
    "Travel Time to Work",
    "Household Income",
    "Average Household Size",
    "Vehicles Available",
    "Occupation",
    "Industry",
    "Education",
    "Poverty Status",
    "Race",
    "Hispanic or Latino ",
    "Disability Status",
    "Language Spoken at Home",
    "Employment Status",
    "Median Gross Rent"
  ),
  `Derived Variables` = c(
    "total_population, male_population, female_population, age_under_18, age_18_34, age_35_64, age_65_plus",
    "drive_alone, carpool, public_transit, walk, bike, work_from_home",
    "commute_short, commute_medium, commute_long",
    "income_under_25k, income_25k_75k, income_75k_plus, median_income",
    "average_household_size",
    "no_vehicle, one_vehicle, two_plus_vehicles",
    "occupation variables (aggregated)",
    "industry variables (aggregated)",
    "less_than_hs, hs_diploma, some_college, associates_degree, bachelors_degree, graduate_degree",
    "below_poverty, above_poverty, poverty_rate",
    "white_population, black_population, asian_population",
    "hispanic_population",
    "disability variables (aggregated)",
    "foreign_born",
    "in_labor_force, employed, unemployed, not_in_labor_force, unemployment_rate",
    "median_gross_rent"
  )
)

kable(acs_table_summary, caption = "ACS tables and derived variables.")
```
### **Key Metrics**

The primary risk metric, `crash_rate_per_1000`, measures the number of crashes per 1,000 residents in each census tract by year. This population-adjusted rate follows the methodology of studies that normalize crash counts by population to ensure fair comparisons of relative risk across areas with varying exposure levels \citep{brubacher, cabrera}.

This response variable is modeled alongside the transformed and selected socio-economic and transportation variables detailed in @sec-appA. Together, these variables allow the model to capture both the exposure risk (frequency) and potential cost severity of accidents, aligning with the frameworks used in both insurance \citep{clemente, henckaerts} and traffic safety research \citep{dong}.

#### **Preprocessing**

Crash records from the NYC Open Data MVC dataset are cleaned (removing rows with missing or zero coordinates) and spatially joined to 2020 Census Tracts using official census tract shapefiles. Annual summaries of total crashes, injuries, and fatalities are then aggregated by tract and normalized by tract-level population to compute per-capita crash, injury, and fatality rates. The ACS socio-economic data are harmonized to 2020 tract boundaries (via crosswalks for 2018–2019), binned into interpretable categories, and converted to percentages of total population where applicable. Interaction features-poverty rate and vehicle ownership, as well as unemployment rate and vehicle ownership-were engineered to capture compound effects on risk exposure. 

After examination, a subset of highly correlated variables were removed. Measures of poverty level and population above the poverty line, as well as employment and unemployment percentages, were closely tied to broader income and labor force indicators already included in the model, creating redundancy without improving predictive power. Similarly, metrics describing commuting alone by car and the distribution of vehicle ownership (households with no vehicles, one vehicle, or multiple vehicles) were binned to prevent issues from  being strongly interrelated. The precentage of female share of the population was excluded because of its near-perfect correlation with the male share of the population. The same was true for the share of high-income households (earning above $75,000), which closely overlapped with median income levels. 

No categorical encoding besides `year` or standardization was performed at this stage since all ACS features are already expressed as continuous percentages or numeric values, and gradient boosting models (XGBoost) handle raw scales effectively \citep{henckaerts}. 

### **Modeling Approach**

XGBoost \citep{xgboost} is chosen for its strong track record in insurance risk modeling and interpretability when combined with SHAP \citep{dong}. This model selection aligns with studies comparing boosting frameworks for both frequency-severity modeling \citep{henckaerts} and urban crash prediction \citep{adeniyi}.

Model performance was optimized with hypermater tuning using the automated Bayesian optimization framework Optuna \citep{optuna}. This approach is supported by prior research showing that systematic hyperparameter optimization significantly improves boosting model accuracy \citep{liu}.

Each configuration of Optuna tuning was evaluated using spatial cross-validation at the borough level on the training data to balance bias and variance, ensuring that the model captured meaningful patterns without overfitting or overgeneralizing across geography.

## Results

### **Descriptive Statistics**

The dataset comprises 13,518 census tract–year observations from 2018 to 2023. Population counts vary widely across tracts, with a median of approximately 42,979 residents and extremes ranging from fewer than 100 to over 220,000. 

![Crash Rate by Borough, by Year](plots/crash_rate_by_borough_plot.png)

Crash Rate by Borough shows a clear downward trend in crash rates across all boroughs over time, with a sharp reduction during the COVID-19 pandemic period (2020) and gradual stabilization afterward. Bronx and Queens consistently show higher crash rates per 1,000 residents compared to Staten Island and Manhattan. 

![Crash Rate in 2018 vs 2022](plots/2018_2022_comparison.png)

The geospatial heatmaps illustrate how crash rates are spatially clustered within the city. In 2018, high crash rates were concentrated in central Brooklyn, the South Bronx, and sections of northern Manhattan, while in 2022, these hotspots persisted but appeared less intense overall, consistent with the downward temporal trend post-Covid-19 pandemic. Applying the same color scale across both maps, it is evident that most census tracts saw a reduction in crash intensity, although isolated high-risk corridors remain.

### **Hyperperameter Tuning**

Optuna hyperparameter tuning \citep{optuna} enhanced the predictive accuracy and generalization capability of the XGBoost model. The final configuration represents a balance between model complexity and overfitting risk, as determined by performance on the training and validation subsets.

| Action | Parameter  | Value     |
|---------|-----------|-----------|
| Learning Rate | `eta`  | 1.549545  |
| Tree Depth | `max_depth`  | 4 |
| Row Sampling | `subsample` | 0.5583975 |
| Feature Sampling | `colsample_bytree` | 0.8797697 |
| Minimum Child Weight | `min_child_weight` | 3 |
| Minimum Loss Reduction  | `gamma` | 3.35839 |
| L2 Regularization | `lambda` | 6.131609 |
| L1 Regularization | `alpha` | 2.805485 |

: Optimal Parameters as per Optuna

A tree depth of 4 means the model only splits features a few times before making predictions. The socio-economic and crash-rate features capture patterns that can be learned with relatively few decision boundaries.

This high learning rate is unusually high compared to common XGBoost defaults (0.01–0.3), indicating the model is taking larger steps while fitting each tree. The relatively small dataset (13,518 observations) allows a faster convergence without needing a very gradual learning rate. However, high `eta` combined with shallow trees requires careful monitoring for overfitting, which the regularization terms help mitigate.

The subsampling ratios (`subsample = 0.56`, `colsample_bytree = 0.88`) show the model uses just over half of the rows for each boosting iteration and nearly all features. This randomness prevents any one subset of data from dominating the model and improves generalization. This confirms the dataset has sufficient size and diversity to benefit from row sampling, but not so many redundant features that aggressive column sampling is needed.

Regularization parameters (`lambda = 6.13`, `alpha = 2.81`, `gamma = 3`.36) are relatively strong regularization values, indicating the model needed constraints to avoid overfitting. In practice, this means there is enough correlation and redundancy among features that despite removing highy correlated variables, the model benefits from being penalized for complex splits or large feature weights.

### **Model Performance**

The XGBoost model achieved robust predictive performance on the holdout test set, with the following metrics:

| Metric  | Score     |
|---------|-----------|
| RMSE  | 1.549545  |
| MAE   | 0.8372956 |
| $R^2$ | 0.2595503 |

: XGBOOST Model Evaluation Metrics

The XGBoost model’s evaluation metrics suggest moderate predictive power with stable error bounds on the holdout test set. An RMSE of 1.55 indicates that the model’s predicted crash rates deviate, on average, by roughly 1.5 crashes per 1,000 residents from observed values, with an MAE of 0.84 confirming that most prediction errors are below 1 crash per 1,000 residents. While the $R^2=0.26$ shows that the model explains only about 26% of the variance in crash rates across census tracts, this is consistent with the high degree of randomness and unobserved factors (e.g., driver behavior, weather) inherent in crash data.

![Residual Diagnostic Plots](plots/residuals_diagnostic_grid.png)

#### **Examination of the Residuals**

The predicted vs. actual values plot shows that the model captures the general trend of observed crash rates across census tracts, with most predictions clustering closely around the 45-degree reference line. While a slight underestimation is evident for the highest crash-rate tracts, this is typical for gradient boosting models where extreme outliers are smoothed during ensemble averaging.

The residual density plot indicates residuals are centered near zero with a narrow peak, suggesting minimal systemic bias.

The residuals vs. predicted values plot shows a random scatter around zero, with no strong patterns of heteroskedasticity or underfitting, although a few outlier tracts exhibit residuals above ±10.

### **Global Feature Importance (SHAP)**

![Global Feature Importance with SHAP](plots/pdp/pdp_grid.png)

The SHAP plot highlights the most influential features on crash risk predictions. The top six variables, in order of importance, are:

**Post-Pandemic Indicator**

The pre vs post Covid pandemic indicator variable hows a marked upward shift in predicted crash rates from 2020 onward, consistent with observed pandemic-era changes in traffic dynamics, also observed by \citet{adeniyi}.

**Aging Population**

The PDP plot suggests that areas with a moderate share of elderly residents (10–20%) have slightly lower crash risks, potentially due to lower driving exposure. However, beyond 20%, predicted crash risk rises.

**High School Graduate Population**

For percent of the population with a high school diploma (but no further education), the PDP exhibits a U-shaped relationship: tracts with either very low or very high shares of residents holding a high school diploma are associated with higher crash risk.

**Median Gross Rent**

Median gross rent displays a positive gradient: tracts with higher rents—often denser and more urbanized—show higher crash rates.

**Working Population**

The PDP for percentage of the population in the workforce indicates that crash risk peaks around 60–70% labor force participation. Lower participation areas may have fewer commuters, while areas with higher participation rates may experience higher traffic volumes.

**Poverty Rate x Vehicle Ownership Interaction**

Th variable marking the interaction of vehicle ownership with poverty rate shows that high poverty rates combined with high vehicle ownership strongly elevate crash risk. This finding suggests that economically vulnerable drivers may face both infrastructure and behavioral risks.


![Figure X: Multi-Tree Plot](plots/multi_tree_plot.png)

The multi-tree plot provides a detailed view of how the XGBoost model partitions the socio-economic and transportation variables to predict crash risk, revealing intricate interactions that are not visible in single-variable importance metrics. For insurers and policymakers, this tree-based view offers actionable insights into which combinations of conditions—such as low-income, high-commute areas with dense walking activity—are most predictive of risk. 

At the top of the tree hierarchy, the model consistently splits on the post-pandemic indicator. Subsequent splits emphasize variables such as age distribution, labor force participation, and foreign-born population, all of which indicate that neighborhoods with specific demographic compositions face distinct patterns of risk exposure. For instance, branches that combine higher shares of elderly residents with elevated public transit use or lower workforce participation show heightened predicted crash rates.

Another prominent theme in the tree structure is the role of housing and economic indicators, such as median gross rent and income brackets, which appear alongside transportation variables. The multi-tree pathways involving poverty rate and vehicle ownership interaction are particularly illuminating, as they reveal how economic stress combined with high vehicle reliance amplifies crash likelihood. For example, nodes where the model isolates high poverty rates, high vehicle ownership, and long commutes lead to leaves with some of the highest predicted crash values. 

The branching structure also highlights the interplay between transportation modes and demographics. Variables like walking, biking, and working from home repeatedly appear as secondary splits, indicating that these behaviors act as modifiers of the primary socio-economic risk factors. Areas with high pedestrian activity combined with mid-range incomes or high percentages of young adults tend to diverge from the patterns observed in primarily car-dependent neighborhoods. This reflects the unique urban mobility landscape of New York City, where mixed transportation modes and densely populated corridors create more opportunities for vehicle-pedestrian conflicts.

## Discussion

Although the model’s $R^2$ value of approximately 0.26 indicates that it explains just over one-quarter of the variance in crash rates across New York City census tracts, this is a meaningful achievement considering the inherent randomness of crash events and the absence of individual-level data on drivers, vehicles, road conditions, weather, road design, etc. Auto collisions are influenced by many unobserved factors that cannot be captured through aggregated socio-demographic measures alone. Despite these constraints, the model’s relatively low root mean square error (RMSE = 1.55 crashes per 1,000 residents) and mean absolute error (MAE = 0.84 crashes per 1,000 residents) suggest that it has successfully captured consistent, broad patterns in crash risk that align with socio-economic disparities and urban traffic dynamics.

From a social risk modeling perspective, these results are significant. The SHAP analysis and multi-tree plot reveal that the most influential predictors are not strictly transportation variables but rather socio-economic indicators that shape exposure and vulnerability. The post-pandemic indicator emerges as the single strongest factor, reflecting the profound shift in traffic patterns since 2020, when less congestion but higher average speeds upended previous risk models by changing nearly all traffic conditions, especially in densely populated urban areas like NYC. 

Housing and economic variables also feature prominently. Median gross rent is positively correlated with crash rates, suggesting that denser, higher-cost urban areas within NYC, with more vehicle-pedestrian interactions and complex traffic flows, have elevated risk levels. Similarly, labor force participation peaks as a predictor around 60–70%, reflecting that areas with higher commuter activity experience more traffic and thus more collisions. 

One of the most striking findings is the role of poverty rate and vehicle ownership interaction, which appears consistently in the multi-tree plot. Areas with both high poverty rates and high vehicle availability show notably higher crash risks, likely due to a combination of older vehicles, reduced access to safety infrastructure, and potentially riskier driving environments. 

While the model demonstrates that neighborhood-level demographic and economic factors can act as strong proxies for crash risk, it also highlights critical limitations for deployment in insurance pricing. The moderate R² indicates that a significant portion of risk remains unaccounted for, largely due to unobserved individual-level factors such as driver age, prior claims, and vehicle safety features. Moreover, the use of variables like income, race, or foreign-born population—though statistically predictive—would be highly problematic if directly incorporated into premium calculations due to both legal prohibitions and ethical concerns. These variables risk proxy discrimination, where protected classes are indirectly penalized through correlated socio-economic attributes.

The model answers the primary research question-what socio-economic variables are most strongly predictive of auto insurance risk. It shows that the environmental and demographic facotrs can explain spatial patterns of crashes and provide insurers or policymakers with macro-level risk insights. However, the model cannot, and should not, be used as-is for individual risk assessment. It is better suited for regional portfolio analysis, identifying high-risk neighborhoods for targeted safety interventions, or supplementing traditional actuarial models rather than replacing them.

## Conclusions and Future Work

This research demonstrates that gradient boosting, combined with socio-economic and crash data, can provide interpretable, data-driven insights into auto insurance risk patterns in NYC. By identifying key drivers of crash risk—such as post-pandemic shifts, commuting intensity, and socio-economic vulnerability—the model offers a foundation for both urban safety planning and high-level risk assessment.

The study’s findings also underscore the limitations of using aggregated, public data for underwriting. While the model captures broad trends, it lacks the precision, granularity, and fairness safeguards required for production-level insurance applications. Therefore, the model is best suited as a complementary tool for insurers, providing neighborhood-level risk insights or supporting reinsurance and portfolio management rather than individual pricing.

Future research should focus on three fronts: (1) integrating behavioral data, such as telematics, and weather patterns-among other possible additions-to bridge the gap between macro-level socio-economic patterns and micro-level driving behavior; (2) developing fairness-aware modeling approaches to mitigate bias from socio-economic proxies; and (3) exploring temporal extensions that incorporate evolving risk factors, including post-pandemic traffic patterns and climate-related hazards. These directions will help transition from descriptive social risk modeling to actionable, ethically sound insurance applications.

## Appendix A: Variables Modeled {#sec-appA}
```{r table2}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Key variables, descriptions, and transformations in the final dataset."

library(knitr)

final_variables_summary <- data.frame(
  Type = c(
    rep("Demographic", 6),
    rep("Age", 4),
    rep("Income/Poverty", 4),
    rep("Housing", 3),
    rep("Education", 6),
    rep("Employment", 2),
    rep("Transport", 9),
    rep("Engineered", 3),
    rep("Year", 6)
  ),
  Variable = c(
    # Demographics
    "pct_male_population", "pct_white_population", "pct_black_population",
    "pct_asian_population", "pct_hispanic_population", "pct_foreign_born",
    # Age
    "pct_age_under_18", "pct_age_18_34", "pct_age_35_64", "pct_age_65_plus",
    # Income & Poverty
    "median_income", "pct_income_under_25k", "pct_income_25k_75k",
    "pct_below_poverty",
    # Housing
    "median_gross_rent", "pct_owner_occupied", "pct_renter_occupied",
    # Education
    "pct_less_than_hs", "pct_hs_diploma", "pct_some_college",
    "pct_associates_degree", "pct_bachelors_degree", "pct_graduate_degree",
    # Employment
    "pct_in_labor_force", "unemployment_rate",
    # Commute & Transport
    "pct_commute_short", "pct_commute_medium", "pct_commute_long",
    "pct_carpool", "pct_public_transit", "pct_walk", "pct_bike",
    "pct_work_from_home", "pct_vehicle",
    # Engineered Features
    "post_pandemic", "poverty_vehicle
    _interaction", "unemployment_vehicle
    _interaction",
    # Year Indicators
    "year2018", "year2019", "year2020", "year2021", "year2022", "year2023"
  ),
  Description = c(
    # Demographics
    "Men",
    "Identifying as white",
    "Identifying as black",
    "Identifying as Asian",
    "Identifying as Hispanic/Latino",
    "Foreign-born",
    # Age
    "Under 18",
    "Aged 18-34",
    "Aged 35-64",
    "Aged 65 and above",
    # Income & Poverty
    "Median household income (inflation-adjusted)",
    "Households earning less than $25,000",
    "Households earning $25,000-$75,000",
    "Below the poverty line",
    # Housing
    "Median gross rent (USD)",
    "Owner-occupied housing units",
    "Renter-occupied housing units",
    # Education
    "Less than high school education",
    "High school diploma",
    "Some college education",
    "Associate's degree",
    "Bachelor's degree",
    "Graduate or professional degree",
    # Employment
    "In the labor force",
    "Unemployment rate",
    # Commute & Transport
    "Commute under 15 minutes",
    "Commute between 15-30 minutes",
    "Commute longer than 30 minutes",
    "By carpool",
    "By public transit",
    "By walking",
    "By biking",
    "Working from home",
    "Owns a vehicle",
    # Engineered Features
    "Post-pandemic indicator (1 = 2020 and later)",
    "Interaction term: poverty rate × vehicle ownership",
    "Interaction term: unemployment rate × vehicle ownership",
    # Year Indicators
    "Year dummy: 2018",
    "Year dummy: 2019",
    "Year dummy: 2020",
    "Year dummy: 2021",
    "Year dummy: 2022",
    "Year dummy: 2023"
  ),
  Transformation = c(
    rep("Percentage", 10),
    "Raw value (USD)", "Percentage", "Percentage", "Percentage",
    "Raw value (USD)", "Percentage", "Percentage",
    rep("Percentage", 6),
    rep("Percentage", 2),
    rep("Percentage", 9),
    "Binary", "Interaction", "Interaction",
    rep("Indicator", 6)
  ),
  stringsAsFactors = FALSE
)

kable(final_variables_summary, 
      caption = "Table 2: Key variables, descriptions, and transformations in the final dataset.",
      col.names = c("Variable", "Description", "Type", "Transformation"),
      align = c("l", "l", "l", "l"))
```

## References