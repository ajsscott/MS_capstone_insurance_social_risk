---
title: "XGBoost Modeling R Notebook"
author: "AJ Strauman-Scott"
date: "`r Sys.Date()`"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(caret)
library(xgboost)
library(SHAPforxgboost)
library(Matrix)
library(doParallel)
```

## LOAD DATA

```{r load-data}
df <- read_csv("../data/model-ready/social-risk-crash-rate-data.csv") %>%
    select(-geoid)
glimpse(df)
```

## PREPARE FEATURES AND TARGET

I'm keeping `year` as a Numeric Feature. If thereâ€™s a clear trend in crash risk over time (e.g., fewer crashes post-pandemic), keeping `year` numeric allows the model to capture this trend. XGBoost will treat it as a continuous variable, creating splits like `year < 2020`.

If, after modeling, I think each year is qualitatively different (e.g., due to policy changes or pandemic impacts), I will treat `year` as a factor and one-hot encode it. Also, instead of using raw years, I could create a `years_since_2018` variable:

df <- df %>%
  mutate(years_since_2018 = year - 2018)

We will remove all possible target variables and keep only one per model training.

```{r single-target-df}
# Choose your target variable (e.g., crash rate per 1,000 residents)
target_var <- "crash_rate_per_1000"

# Remove all target variables except selected
cols_to_remove <- grep("crash|_injured|_killed|per_1000", 
                       names(df), 
                       value = TRUE)
cols_to_remove <- setdiff(cols_to_remove, target_var) # keep this column

df <- df %>% select(-all_of(cols_to_remove),)

# Create feature matrix and target vector
X <- df %>% select(-one_of(target_var))
y <- df[[target_var]]

```

## TRAIN/TEST SPLLIT

```{r train-test-split}
# Set seed
set.seed(2025)

# Split by index
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
y_train <- y[train_index]
X_test <- X[-train_index, ]
y_test <- y[-train_index]

# Prepare data for caret using only the training set
train_data <- as.data.frame(as.matrix(X_train))
train_data$target <- y_train
```

## HYPERPARAMETER TUNING

```{r tune-params}
# Define tuning grid
xgb_grid <- expand.grid(
  nrounds = c(100, 300, 500),
  eta = c(0.01, 0.05, 0.1),
  max_depth = c(4, 6, 8),
  gamma = c(0, 1),
  colsample_bytree = c(0.7, 0.8),
  min_child_weight = c(1, 3),
  subsample = c(0.7, 0.8)
)

# Cross-validation setup
ctrl <- caret::trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE,
  allowParallel = TRUE
)

# Set seed
set.seed(2025)

# Tuning with parallel processing
xgb_tune <- caret::train(
  target ~ .,
  data = train_data,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = xgb_grid,
  metric = "RMSE",
  nthread = detectCores() - 1
)

# Store best params
best_params <- xgb_tune$bestTune
```

```{r save-params}
# Save the best_params object as an RDS file
saveRDS(best_params, file = "../data/model-ready/xgb_best_params.rds")

# Save best_params (and other objects) into an RData file
save(best_params, file = "../data/processed/xgb_best_params.RData")
```

## TRAIN MODEL

```{r train-model}
# Conver to xgb.DMatrix
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)

# Set seed
set.seed(2025)

# Training with parallel processing
final_model <- xgboost(
  data = dtrain,
  nrounds = 1000,  # Set higher when using early stopping
  early_stopping_rounds = 20,
  watchlist = list(train = dtrain, test = dtest),
  params = list(
    eta = best_params$eta,
    max_depth = best_params$max_depth,
    gamma = best_params$gamma,
    colsample_bytree = best_params$colsample_bytree,
    min_child_weight = best_params$min_child_weight,
    subsample = best_params$subsample
  ),
  objective = "reg:squarederror",
  eval_metric = "rmse",
  verbose = 1,
  nthread = detectCores() - 1
)
```

## MODEL EVALUATION

```{r eval-model}
# Predict on test set
preds <- predict(final_model, as.matrix(X_test))

# Calculate RMSE
rmse <- sqrt(mean((y_test - preds)^2))
cat("Test RMSE:", rmse)

# Plot predicted vs. actual
data.frame(actual = y_test, predicted = preds) %>%
  ggplot(aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  theme_minimal() +
  labs(title = "Predicted vs Actual Crash Rates")
```

## SHAP EXPLAINABILITY

```{r shap}
# Compute SHAP values
shap_values <- shap.values(xgb_model = final_model, X_train = as.matrix(X_train))
shap_long <- shap.prep(shap_contrib = shap_values$shap_score, X_train = as.matrix(X_train))

# SHAP summary plot
shap.plot.summary(shap_long)
```
